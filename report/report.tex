\documentclass[a4paper,12pt]{article}
%\usepackage{fullpage}
%\usepackage{a4wide}
\usepackage[utf8]{inputenc}
\usepackage[danish, english]{babel}

% Nice looking font
%\usepackage{palatino}

% Minitoc - mini table of contents
\usepackage{minitoc}

% In order to highlight code
\usepackage[pdftex]{color}
\usepackage{listings}

% For graphics support
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{subfigure}

% Math support
\usepackage{amsmath}
\usepackage{amssymb}

% In order to include pdf
\usepackage{pdfpages}

% Graf support
\usepackage{tkz-graph}

% Pdf section support
\usepackage{hyperref}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    unicode=false,          % non-Latin characters in Acrobat's bookmarks
    pdftoolbar=false,       % show Acrobat's toolbar?
    pdfmenubar=false,       % show Acrobat's menu?
    pdffitwindow=true,      % page fit to window when opened
    pdftitle={OCamlCSP - A concurrency library for OCaml}, % title
    pdfauthor={Joakim Ahnfelt-Rønne - 1986/03/14 - joakim.ahnfelt@gmail.com,
        Ramón Salvador Soto Mathiesen - 1979/05/15 - ramon@diku.dk and
        Advisor: Andrzej Filinski - andrzej@diku.dk}, % author
    pdfsubject={},   % subject of the document
    pdfnewwindow=true,      % links in new window
    pdfkeywords={keywords}, % list of keywords
    colorlinks=false,       % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

% Macros
\newcommand{\missing}[1]{
  \begin{tabular}{|p{11cm}|}
    \hline
    \emph{Missing:} {\scriptsize (things that need to be written or considered)} \\
    \hline
    #1
    \hline
  \end{tabular}
}

\newcommand{\runtest}[1]{
  \footnotesize
  \framebox[14.5cm][l]{#1}
  \normalsize
}

\newcommand{\includecode}[2]{
  \definecolor{stringcolor}{rgb}{0.50,0.00,0.50}      %
  \definecolor{commentcolor}{rgb}{0.00,0.50,0.00}     %
  \definecolor{keywordcolor}{rgb}{0.00,0.00,1.00}     %
  \definecolor{idcolor}{rgb}{0.00,0.00,0.00}          %
  \lstset{language=ML,basicstyle=\ttfamily,keywordstyle=\color{keywordcolor},
    commentstyle={\color{commentcolor}\itshape},
    stringstyle={\color{stringcolor}},
    identifierstyle=\color{idcolor},numbers=left,
    xleftmargin=2em,% framerule=0.8pt,
    stepnumber=1,frame=tlrb,showstringspaces=false,
    firstnumber=1,numberstyle=\ttfamily, breaklines}

  \normalsize
  #1:
  \scriptsize
  \lstinputlisting{#2}
  \normalsize
}

\newcommand{\includeoutput}[2]{
\definecolor{allblackcolor}{rgb}{0.00,0.00,0.00}      %
\lstset{basicstyle=\ttfamily,keywordstyle=\color{allblackcolor},
        commentstyle={\color{allblackcolor}\itshape},
        stringstyle={\color{allblackcolor}},
        identifierstyle=\color{allblackcolor},numbers=left,
        xleftmargin=2em,% framerule=0.8pt,
        stepnumber=0,frame=tlrb,showstringspaces=false,
        firstnumber=1,numberstyle=\ttfamily, breaklines}

  \normalsize
  #1:
  \scriptsize
  \lstinputlisting{#2}
  \normalsize
}

% Opening
\title{OCamlCSP - A concurrency library for OCaml}
\author{Joakim Ahnfelt-Rønne - 1986/03/14 - joakim.ahnfelt@gmail.com \and 
        Ramón Salvador Soto Mathiesen - 1979/05/15 - ramon@diku.dk \and
        \\ Advisor: Andrzej Filinski - andrzej@diku.dk}
\date{31$^{st}$ July 2009}

\begin{document}

\maketitle

\newpage
\selectlanguage{english}
\begin{abstract}
We present a concurrency library for the non-lazy impure functional language
OCaml. It is inspired by Communicating Sequential Processes \cite{hoare} and a
selection of existing libraries that are based on CSP. The library provides a
hierarchical process model and a construct for waiting on input and output
from/to an arbitrary number of channels. The implementation is based on OCaml's
threads and thus allow for concurrency and overlapping I/O, but not for true
hardware parallelism. We provide reusable processes built on top of the library
as well as a non-trivial application in the form of a web proxy.
\end{abstract}

\newpage
\setcounter{tocdepth}{2}
\setcounter{secttocdepth}{3}
\dosecttoc \tableofcontents
\newpage

% Line breaks between paragraphs instead of indentation
\parindent=0pt
\parskip=8pt plus 2pt minus 4pt

\section{Introduction}
During a course on Communicating Sequential Processes \cite{hoare} in theory and
practice (specifically Extreme Multiprogramming 2009 at Department of Computer
Science, Copenhagen University), we were introduced to multiple concurrency
libraries based on CSP. However, none of them supported any of the languages in
the ML family (these are strict, impure functional programming languages).

The library presented in this document is for the ML variant OCaml, and is
inspired by CSP and the existing libraries based on CSP (including
\cite{pycsp}, \cite{jcsp}, \cite{cppcsp2} and \cite{chp}). The design choices
are explained and documentation and source code is provided.

We base our implementation on the standard OCaml Threads library. Due to the
lack of a concurrent garbage collector, these do not support true hardware
parallelism (see appendix \ref{appendixSysthreads}). However, it does provide
concurrency and overlapping I/O (see appendix \ref{appendixThreadunix}).

As a demonstration of a non-trivial application built with the library, we
provide a web proxy with caching. This example takes advantage of overlapping
I/O and shows how to use the library in conjunction with sockets. We provide a
number of reusable processes for computation as well as for treating sockets as
channels. As an example of the computation processes, we provide a process
that writes the Fibonacci series to a channel. 

We provide channels that may be read from or written to by any number of
processes, alternation with both read and write guards, a hierarchical
process model, and a method for terminating process networks.

The final API has some similarities with the \emph{Event} module in the
standard OCaml library. However, that library is based on Concurrent ML and
uses a model with first class composable events. It does not provide any
process model and no special support for termination of process networks.

Most of the text is a discussion, so if you just want to know how to use the
library, the fastest way to get acquainted with it is probably to read the
documentation in appendix \ref{appendixDoc}, the source code for computation
processes in \ref{appendixLegoland} and the source code for the web proxy in
\ref{appendixProxy}.

The full source code and this report is also available online at:
\begin{center}
http://github.com/Ahnfelt/mlcsp/
\end{center}

\newpage
\section{API design}
\label{apidesign}

The CSP theory is concerned with processes that communicate solely by synchronous 
events. Synchronous channels are built on top of the basic abstraction, and this is
what most implementations (including \cite{occam}, \cite{chp}, \cite{cppcsp2},
\cite{jcsp}, \cite{pycsp} and this one) provide for communication. Additionally,
it is possible to wait for communication from multiple sources at once.

For each construct, we are going to look at how it's done in CSP and in some of
the existing CSP libraries, how we would like to write it in OCaml, and what
the semantics should be. We will use the explicit module prefix \verb|Csp.| in
front of any functions that come from our core API.

We have tried to make the API as small as possible. Given an equal quality of
documentation, it is easier to learn a small number of functions than a large;
and if we have less functions to consider, we can spend more time improving the
quality of the documentation of each of them. The core \verb|Csp| module has
been kept small by excluding everything that wasn't either CSP-like or required
access to the internal data structures. Utility functions that didn't fit this
description have been put in the \verb|Cspu| module (see appendix
\ref{appendixCspu}).

\subsection{Processes}
Processes can be run concurrently in CSP using the $\parallel$ operator:
\[P \parallel Q\]
They may communicate with each other. If put in front of another process in a
sequence, all these processes running concurrently must finish before the next
process can take any steps.

In PyCSP running two processes concurrently looks like this:
\begin{verbatim}
Parallel(P, Q)
\end{verbatim}
Where $P$ and $Q$ must be specified as $Process$ instances. There may be more processes
separated by commas. It runs the processes concurrently and returns when they
have all stopped executing. The API for C++CSP2 and JCSP are similar. In all
cases the process objects only expose a \emph{run} method. It is unclear what
happens if this method is called twice on the same instance (especially if the
instance is used twice in the same parallel-construct).

To avoid that kind of undefined behaviour we do not provide handles to 
\emph{running processes}.
A process is simply any OCaml expression, although since OCaml is
call-by-value we use functions to suspend the evaluation of them until their
side effects are desireable (if ever). Our parallel construct looks like this:

\begin{verbatim}
Csp.parallel [
    (fun () -> ...);
    (fun () -> ...);
]
\end{verbatim}

Even though the construct is called \emph{parallel}, there is no guarentee that
they actually run in parallel on the hardware. In particular, our implementation
does not support this. However, it does guarentee that the processes will be run
concurrently.

With the parallel construct, every process can be said to be a \emph{subprocess}
of some other process, meaning that it blocks the process until it finishes.
Like in CSP, this makes for a hierarchical process model where all processes are
in some sense contained within another process.

Note that processes share memory and can share any kind of OCaml values, which
it may get a handle to via OCamls standard scoping rules or any other way a
value can travel in a shared-memory environment. Although you can also share
mutable state this way, we don't recommend this since it requires careful
syncronization beyond the scope of this library. There seems to be no obvious
way to limit side effects in OCaml's type system.

We use a list so it is possible to specify any number of processes. The 
\verb|(fun ...)|s may be any OCaml expression, although we require that they are of type
$unit \to unit$. Since OCaml has anonymous functions, we can define the process directly 
inside the parallel construct, which is often convenient for small processes. The processes
are then run concurrently, and there is no way to get a handle to a running
process through our API.

{\it Parallel} only returns once all the processes have finished executing. A
process may finish either by returning or by throwing an exception. In the
latter case, we have to decide what to do with the exception. We can throw it
away, but then we can't detect the exception and handle it outside the parallel
construct. We could build up a list of exceptions, and attach data so it's
possible to handle exceptions from each thread separatly. However, this fine
grained handling can already be done individually within each process. We
therefore pick one of the exceptions thrown (if any) and rethrow that. 

The question is then, how to pick
one of potentially many exceptions? One possible option is to pick the first
exception that is thrown, since this may be the cause of exceptions thrown later
by the other processes. However, then you would have to decide which one is
{\it first}, which isn't clear when multiple processes are running concurrently.
You could also choose the exception from whichever of the throwing processes
comes first in the list passed to parallel. This gives the programmer some
control over which of the processes that might throw the exceptions that are
most important to handle. However, this kind of control can already be obtained
by handling the exceptions in each process individually. We therefore say that
an arbitrary exception will be picked if multiple processes are thrown. This
might result in an easier implementation.

Being a functional language, it may be convenient to collect the \emph{return
values} of processes. Consider the following CSP (assuming global scoping for
$x$ and $y$ for the purpose of this example):
\[(c_1\,?\,x \to SKIP \parallel c_2\,?\,y \to SKIP); c_3\,!\,(x + y)\]
The intention of this is to read from $c_1$ and $c_2$ concurrently, and then
send the sum via $c_3$. Consider a construct $parallel2$ that takes a pair 
$(unit \to \alpha) \times (unit \to \beta)$, runs the two processes
concurrently, and returns a pair $\alpha \times \beta$ containing the return
value of each process. Then we could write:

\begin{verbatim}
let (x, y) = parallel2 (
    (fun () -> Csp.read c1), 
    (fun () -> Csp.read c2)
) in Csp.write c3 (x + y)
\end{verbatim}

However, we can implement this using the parallel construct that throws away
the result, by using extra channels like this:

\begin{verbatim}
let c1' = Csp.new_channel () in
let c2' = Csp.new_channel () in
parallel [
    (fun () -> Csp.write c1' (Csp.read c1));
    (fun () -> Csp.write c2' (Csp.read c2));
    (fun () -> Csp.write c3 (Csp.read c1' + Csp.read c2'));
]
\end{verbatim}

You could generalize this to derive \emph{parallel2} from \emph{parallel}. You
could also derive \emph{parallel} from \emph{parallel2}. Thus, in the name of
minimalism, we want to provide the most useful one, and then leave it to the
user to define the other one if she needs it. We had both versions in the API
during development of the example code in section \ref{examples}. The above code
is the only compelling use case for \emph{parallel2} we could identify, so we
chose to provide \emph{parallel} which we have used throughout the code base.

JCSP has the ability to \emph{spawn} processes (via its \emph{ProcessManager})
whose lifetime are not related to the process that spawns them. This makes for
a flat process model. There is already direct support for it in the standard
OCaml Thread library. We don't provide it in our API, since it doesn't
correspond to anything in CSP, and it can be hard to keep track of the lifetime
of processes if there is no hierarchy.

We don't provide a special construct for sequence, since OCaml has a perfectly
fine sequence operator built in, and executing a list of processes in sequence
is a simple matter of iterating over it and invoking each one. We also don't
provide a way to specify the stack size for a process, because the stack grows
dynamically in OCaml's VM-level threads. With system threads, the amount of
threads that you can spawn seem rather limited (see section
\ref{testMaxthreads}), so stack size will not be the limiting factor.

\subsection{Channels}

Channels are the only means of communication between processes that we provide
(except for the shared state that we can't prevent).
In PyCSP, C++CSP2 and JCSP, channels are created by constructing an instance of a channel
class. Our channels correspond to their \emph{any-to-any} channels, meaning that any number
of processes can send on and receive from a channel. However, any message has exactly 
one sender and one receiver, and communication is synchronous.

Creating a channel is just a call to a function which returns the new channel:
\begin{verbatim}
let c = Csp.new_channel ()
\end{verbatim}

Two of the basic constructs for CSP channels are send and receive:
\[c\,!\,e \to ...\]
\[c\,?\,x \to ...\]
Where $c$ is a channel, $e$ is an expression, $x$ is a name and the $...$s are processes. 
The semantics of these are to synchronously send or receive a value respectively, and
then become another process. In the case of receive, the process may refer to the
received value by the name $x$.

In PyCSP, these two constructs look like this:
\begin{verbatim}
c.write(e)
...
\end{verbatim}
\begin{verbatim}
x = c.read()
...
\end{verbatim}
It's using methods to realize the read/write, and sequence to realize \emph{becoming}
another process after the synchronization. Note that the channels are values, whereas
they are names in CSP. JCSP and C++CSP2 are similar.

The obvious way to look like CSP is to define operators ! and ? that work like the
CSP counterpart. However, it is not possible in OCaml to declare that the right hand 
side of the question mark introduces a binding. It is also not desireable to redefine
the ! operator that is used for dereferencing mutable references in OCaml.

We therefore have to decide between methods and functions. The OCaml standard library
primarily uses functions to provide its functionality, and few if any other ML 
variants share OCaml's object model. Since we don't anticipate any need for an
exstensible inheritance hierachy for channels, we choose functions for the task.
We use the \textbf{let in} construct to provide binding.

\begin{verbatim}
Csp.write c e; ...
\end{verbatim}
\begin{verbatim}
let x = Csp.read c in ...
\end{verbatim}

Note that channels are typed, which is also the case in C++CSP2, but not
really in JCSP (that doesn't use generics) and not at all in PyCSP (which has
no static type system).

The remaining semantic details of the channels are explained in the following
section.

\subsection{Alternation}
Alternation is similar to \emph{external choice} in CSP:
\[(c_1\,?\,x \to ...\ |\ c_2\,?\,y \to ...\ |\ c_3\,!\,e \to ...)\]
This construct lists any number of alternative guarded processes
separateoperandsd by $|$. The semantics is that once one or more of the
alternatives can take a step, then an arbitrary one of these is chosen to take
a step, and then the whole process acts as the remainder of the chosen
alternative.

In PyCSP it looks like (where in1 = c1.read, in2 = c2.read, out3 = c3.write):
\begin{verbatim}
s = Alternative(in1, in2, out3).priSelect()
if s == in1:
    x = in1()
    ...
elif s == in2:
    y = in2()
    ...
else:
    out3(e)
    ...
\end{verbatim}
Here $s$ becomes one of $in1$, $in2$ and $out3$, which are \emph{channel ends}. These are instances
of ordinary classes that define a special method that allows for the call-like syntax above.
The JCSP and C++CSP2 selects take in a list of guards and return the index of the guard, which you can 
then switch on. In both cases, you have to \emph{promise} to read from the chosen channel, or the 
behaviour will be undefined.

Starting from CSP's syntax, we might want to write something like \texttt{(A | B | C)}, where $A$, $B$
and $C$ are processes. One might define an operator $|$ that takes two processes and returns the result 
of the one that is chosen. The problem with this is that it is very hard in plain OCaml to inspect 
functions at runtime to see which one of them can take a step.

The existing libraries solve this by providing \emph{guards}, which exposes the first action as a value 
that can easily be inspected by the library. After a guard is selected, the action it specifies must be 
carried out, and it is the programmer's responsibility to ensure this. In the case of PyCSP, channel
ends are also read- or write guards. 

Placing the responsibility on the programmer will lead to bugs if the programmer
fails to obey the requirements. To avoid this, we instead provide \emph{guarded
processes}, which combine the guard and the corresponding actions, similarly to
CSP. Each possible first action has its own constructor, and is automatically
carried out when the guard is chosen. We use a list instead of an operator in
order to provide a more natural syntax for alternation between more than two
guarded processes.

Our alternation construct is intended to capture the conditional logic which typically follows 
alternation in the existing CSP libraries.

\begin{verbatim}
Csp.select [
    Csp.read_guard c1 (fun x -> ...);
    Csp.read_guard c2 (fun y -> ...);
    Csp.write_guard c3 e (fun () -> ...);
]
\end{verbatim}

Whereas external choice in CSP is between processes, our alternation is between guarded processes.
The \verb|(fun ...)|s can be any OCaml expression. The read guards require that the expression is of type
$\alpha \to \beta$ where $\alpha$ is the type of messages that can be sent over the guard's channel, whereas
for the write guards it must be of type $unit \to \beta$. The $\beta$ types must be the same for all guards in 
a list. It will return the result of evaluating the chosen guarded process.

Note that you can have multiple guarded processes that wait on the same
channel. This is similar to \emph{internal choice} in CSP:

\[(c\,?\,x \to ...) \sqcap (c\,?\,x \to ...)\]

This means that the implementation may chose whichever of the alternatives
that are convenient. The combination of external and internal choice is actually
similar to \emph{general choice} in CSP (although our operand processes must be
guarded).

In CSP, any process that can take a step may be chosen arbitrarily. However, if
the same list of alternatives is used in a loop, this might lead to starvation.
If one of the guards is always ready, an arbitrary choice can be to chose this
one every time. This means that any other guards that are ready will be skipped
indefinatly, and thus be starved.

We solve this by prioritizing the guards in a random order each time select is
called. That way the
chance that a ready guard is not taken approaches zero as the number of calls to select grows.

If multiple processes repeatily wait to act on the same channel, and one process is chosen every time,
the other processes will be starved. We solve this by serving processes wating on any given channel
on a first come, first served basis.

Note that this is also a valid behaviour of the arbitrary choice, which we don't
provide separatly. Providing this as the arbitrary choice alternation is
beneficial because a program cannot accidentally depend on an undocumented
order of prioritization. On the other hand, it does incur a small overhead on
every call to select.

Occam specifies \emph{PRI ALT} as follows \cite{occam}:
\begin{quote}
The inputs which guard alternatives in an alternation may be given 
a selection priority. Priority is determined by textual order, the 
alternative appearing first having the highest priority for 
selection. Consider the following example:
\begin{verbatim}
PRI ALT
  disk ? block
    d ()
  keyboard ? char
    k ()
\end{verbatim}
This priority alternation will input values from the channel disk 
in preference to inputs from the channel keyboard. If both channels 
disk and keyboard become ready then disk will be selected as it has 
the highest priority.
\end{quote}

Occam does not have output guards, but if they are added, as they
are in most CSP libraries, the meaning of PRI ALT is no longer clear:
\begin{verbatim}
PAR
  PRI ALT
    c1 ? data
      P ()
    c2 ! data
      Q ()
  PRI ALT
    c2 ? data
      P ()
    c1 ! data
      Q ()
\end{verbatim}

The problem is which communication to chose? It seems the specification of
\emph{PRI ALT} says that \emph{both} must be selected, which contradicts the
semantics of any \emph{ALT} that \emph{one} of them will be chosen.
JCSP supports output guards and refer to \emph{PRI ALT} in its
\emph{priSelect} definition. CHP supports it, but avoids specifying the
relative priority between guards of the read or write variety. We choose not to
offer \emph{priSelect} because its semantics are unclear to us.

The existing processes provide skip guards that are always ready, which is
mostly useful in the bottom of a \emph{priSelect} in order to \emph{poll} the
alternatives. If none of them are ready, the skip guard will be reached and the
priSelect will return without blocking. In case of our select, a skip guard
cannot be given the lowest priority, since all alternatives have equal
priority. However, if a select with a skip-guard like guarded process is used
in a loop, it will never block, allowing the process to perform other tasks
while waiting for one of the guarded processes to become ready. A ready
alternative may be skipped any number of times due to skip being chosen
repeatidly, but it becomes less and less likely that it will be starved in this
sence as the number of calls to select grows. Polling in a loop like this may
lead to busy waiting or multiple responsibilities for a single process. We
don't provide special support for it, but a skip-like construct can be
implemented on top of the library by using a channel, that some process writes
to in a loop, and then using the channel in a read guarded process.

JCSP and C++CSP2 both provides a construct called \emph{fairSelect}, which has
slightly different specifications in the two libraries. The intended semantics
seems to be that if the alternatives are ready in an equal number of calls to
select, no one alternative is chosen again before all other alternatives have
been chosen. This requires that a history is maintained over which guards have
been chosen. We don't provide this since our select should approach this
behavior given sufficient invocations.

We don't provide {\it time guards} since it can be done by creating process
that waits for the desired interval and then writes to a channel, which
process, you can then wait to read from.

The \emph{read} and \emph{write} functions are semantically equivalent to a 
select that has exactly one guard.

The semantics of the select so far is to block until one of the guards become
ready. The obvious
way to define a select with no guards at all is therefore to block indefinatly,
causing a deadlock.
Preferably, the thread would not take up any further resources in this case (since it's trivial to 
detect), and thus we attempt to terminate the thread by throwing an exception. If stack traces are
enabled, and the empty select is an error, this might also provide the programmer with more information
to determine where the error occured.

In JCSP and C++CSP2 you can provide a list of flags that specify if a guard is
active or inactive. We provide similar functionality in the utility module Cspu,
appendix \ref{appendixCspu}, except it takes a list of optional guarded
processes instead of separate lists of flags and guarded processes:

\goodbreak
\begin{verbatim}
let conditional_select l =
    let l' = List.filter (fun cg -> cg <> None) l in
    let l'' = List.map (fun (Some gp) -> gp) l' in
    Csp.select l''
\end{verbatim}

Since we can pass None for guarded processes that aren't enabled, we can avoid
calculating the values that disabled write-guarded processes could have sent if
they were enabled. This is useful because in some cases, it is not possible to
calculate such a value if the condition is false. As an example, consider the
buffer process that may write when its buffer is not empty and may read when its
buffer is not full:

\goodbreak
\begin{verbatim}
let rec buffer i o n l =
    conditional_select [
        (if l <> [] then Some (
            Csp.write_guard o (List.hd l) (fun () -> 
                buffer i o n (List.tl l)
            )
        ) else None);
        (if List.length l < n then Some (
            Csp.read_guard i (fun h -> 
                buffer i o n (l @ [h])
            )
        ) else None);
    ]
\end{verbatim}

This avoids trying to take the head of the list when it is empty.

\subsection{Termination of process networks}
Since few applications run forever, termination of process networks should be
considered.

A way to implement this is to send a special termination message. However,
that requires insertion of termination logic for every communication where the
process might receive a termination message. Additionally, if the readers want
to terminate the writers of a channel, it will often require a dedicated channel
just for termination messages.

If there are multiple processes that listen on a channel, it would also be hard
to ensure that they had all received the termination message before the process
sending it shuts down. To keep track of this you might need to know the number
of processes that are listening or are going to listen on the channel, which
might not even be possible to determine. The process that wants to send the
terminating process could loop forever, repeating the termination message to
anybody who read from the channel, but then that process could never shut down.

In PyCSP, JCSP and C++CSP2, a channel may be \emph{poisoned}. Once a channel
has been poisoned, reading from or writing to that channel causes an exception.
The exception may be handled, thus allowing the process to clean up, propagate
the poison, or even ignore the poisoning. That way, the process remains in
control of its own lifespan. A channel that has been poisoned can never become
unpoisoned. We provide the same construct:

\begin{verbatim}
Csp.poison c 
\end{verbatim}

Read and write guards become ready if their channel is poisoned, and an
alternation may thus chose to throw a \emph{PoisonException} if one or more of
its guards' channels are poisoned.

In order to shut down process networks, which may have internal subnetworks, it
is nessecary to propagate the poison to the other processes in the network. As
mentioned, this can be done in the handler for PoisonException. PyCSP
automatically poisons channels that are arguments to process constructors. In 
the following PyCSP example:
\begin{verbatim}
def foo(in,out):
    while True:
        x = in()
        out(x)
        
        poisonChannel(in)
\end{verbatim}
Even if we only poison the input channel, as soon as we try to read again on
the input channel then we get poisoned and throw a poison exception. By doing
this we then iterate through the parameters in the constructor checking if
they are channels, if they are we poison. In our example we have the {\it in}
and {\it out}, both get poisoned and hereby we have propagated the poison
received by the input channel. For more information on this, look at
\cite{pycsp}.

In many cases this is the desired behaviour. JCSP and C++CSP2 do not provide it,
and neither do we due to technical issues (see section \ref{implementation}).

\subsection{Permissions}

PyCSP, JCSP and C++CSP2 provide a concept called \emph{channel ends}, which are
handles to channels though which you can only read or only write (or some other
set of permissions). This is useful for specifying what a process might do with
a channel, so unintended use of a channel can be caught early.

It can be done via the static type system as in JCSP and C++CSP2 or as a dynamic
check as in PyCSP. In the name of detecting the unintended use as early as
possible, we want to provide a static check. We provide this through a set of
functions, each of which takes a channel returns a handle with only a specific
set of permissions:

\begin{verbatim}
let i = Csp.read_only c
\end{verbatim}

It is a compile time error to attempt to write to or poison the returned handle.
The permissions are provided purely through the type system, and none of the
functions can add permissions. See secion \ref{implementation} for the complete
set.

\newpage
\section{Implementation}
\label{implementation}

Our implementation does not use any type casts or other features that
circumvent the type system. We use functions to hide differing type variables
whenever we need to put them in lists or similar.

The source code for the library can be seen in appendix \ref{appendixAPI}.

\subsection{Channels and alternation}
A \emph{one-to-one} channel is a channel that only allows one procees to read from it
and one process 
to write to it. It may be implemented as a state machine as shown in figure \ref{channel-state}.
When the channel is in the NobodyWaiting state and a process tries to read from the channel,
it enters the ReaderWaiting state. When a writer comes along and tries to write to a channel
in this state, it returns to the NobodyWaiting state, transfers the message, and only then
allows the two processes to continue. The WriterWaiting state works in much the same way.

\begin{figure}[h]
\centering
    \begin{tikzpicture}[node distance   = 5 cm]
      \GraphInit[vstyle=Normal]
      \tikzset{LabelStyle/.style =   {draw}}
      \SetVertexNormal[TextColor = white,
                       LineColor = white]
      \Vertex{Start}
      \SetVertexNormal[Shape = circle,
                       TextColor = black,
                       LineWidth = 2pt]
      \SOEA(Start){NobodyWaiting}
      \SOWE(NobodyWaiting){ReaderWaiting}
      \SOEA(NobodyWaiting){WritterWaiting}
      \SetUpEdge[style={->,bend right,ultra thick},labelstyle = {draw}]
      \Edge[label=read](NobodyWaiting)(ReaderWaiting)
      \Edge[label=write](NobodyWaiting)(WritterWaiting)
      \SetUpEdge[style={->,bend right,ultra thick},labelstyle = {draw}]
      \Edge[label=write](ReaderWaiting)(NobodyWaiting)
      \Edge[label=read](WritterWaiting)(NobodyWaiting)
      \SetUpEdge[style={->,bend left,ultra thick}]
      \Edge(Start)(NobodyWaiting)
    \end{tikzpicture}
\caption{Simplified channel state (poison and multi-read/write not shown)}
\label{channel-state}
\end{figure}

From any state, the channel might be poisoned and enter the Poisoned state. If it was in the
ReaderWaiting or the WriterWaiting state, the waiting process will wake up and throw a special
exception. Any further attempts to read from or write to the channel will result in this 
exception being thrown again.

\emph{Any-to-any} channels places no restrictions on the number of processes that can
read from or write to it. To implement these we extend the above to keep a queue
of readers (when in the ReaderWaiting state) or writers (when in the
WriterWaiting state).

The choice of using a queue gives a stronger guarentee than CSP gives, namely that no processes
will be starved. By starvation we mean to say that a process waiting to read or write on the
channel can be blocked indefinately even though an infinite number of messages is transmitted
over the channel. This would happen with a stack if another process is always ready to read or 
write again before the channel was ready to accomodate the starving process. The starving process
would always be put behind the eager process with a stack, but with a queue, the starving process
will always advance in the queue every time a message is transmitted, guarenteeing that it will
eventually get its turn.

\goodbreak
The internal state for channels looks like this:

\begin{verbatim}
type 'a channel_state
    = NobodyWaiting 
    | ReaderWaiting of (Condition.t * ('a -> unit)) list
    | WriterWaiting of (Condition.t * (unit -> 'a)) list
    | Poisoned
\end{verbatim}

Both readers and writers have a condition variable that they are waiting on
while in the queue. Readers have a function that when given a value may perform
a side effect $(\alpha \to unit)$, and writers have a function that may perform
a side effect and then returns the value to be written. These functions are
only supposed to be called when transmitting a value. The side effects in both
cases is to change the internal state of the waiting process and to remove it
from all the channels it is waiting on. The state change is such that the
process can tell that the transmit has happened, thus allowing it to continue.
In the case of the readers, it stores the value transmitted.

A process registers itself for reading or writing on any number of channels via
the select construct, which takes a list of guarded processes. It augments each
with a condition variable unique to the process. Then shuffles the list in order
to avoid starvation as discussed in section \ref{apidesign}. It checks if any
of the channels associated with the guarded processes are poisoned, and if
that is the case, throws a PoisonException. This is done by calling
\emph{check\_poison} for each of them, which is part of the following record:

\begin{verbatim}
type 'a concrete_guard = {
    attempt: unit -> (unit -> 'a) option;
    check_poison: unit -> bool;
    subscribe: ('a concrete_guard) list -> 
        ((unit -> 'a) option) ref -> unit;
    unsubscribe: unit -> unit;
}
\end{verbatim}

Otherwise it calls \emph{attempt} on each of them until one succeeds.
When \emph{attempt} succeeds, it carries out a transmission and returns $Some\
f$ where $f$ is a function that when called carries out the process part of the
guarded process and returns its result. Otherwise it returns $None$. If any of
them succeeds, $f$ is applied (to unit) and the result is returned.

If none of the attempts succeed, it \emph{subscribes} each guarded process.
This means creating a function that fits into the channel waiting queue
as discussed earlier, and putting it into the queue. Then it enters a loop
where it waits on the process' condition variable each iteration. When woken up
due to a signal on the condition variable, it checks if it has been involved in
a transmission, and if so exits the loop and executes the process part of the
chosen guarded process.

We use a lock that is global to the library in order to protect the state
associated with channels and processes from concurrent mutation (and
thus race conditions). This lock is only taken when first trying to read from a
channel, or right after a process has been woken up. We claim that this won't
lead to performance degradation, since OCaml's threads only provides concurrency
though time-sharing (see appendix \ref{appendixSysthreads}). The execution of
the process part of guarded processes are done outside this lock since they do
not require it and because they may run for a very long time (or even diverge).

Read and write are implemented as selects with a trivial guarded process:
\begin{verbatim}
let read c = select [read_guard c (fun x -> x)]
let write c v = select [write_guard c v (fun () -> ())]
\end{verbatim}
This is similar to the way CSP defines prefixing as an external choice with one
guarded process.

We considered implementing automatic poison propagation as they provide in
PyCSP. However, they do this by reflectively iterating though the arguments to
the process constructor, checking each if it's a channel, and poisoning it if it
is. We cannot use this strategy since there is no facility for iterating
through the list of arguments to a function. It would also not cover the case
where channels are obtained by lexical scoping.

\subsection{Permissions}

Channel permissions are enforced solely by the type system.

\begin{verbatim}
type ('a, 'b) channel = ('a channel_state) ref
\end{verbatim}

The phantom type 'b is used for the channel permissions. This is represented
with a product of three booleans: \emph{read * write * poison}.
Reading, writing and poisoning are initially enabled for a channel, but handles
with less permissions can be obtained through the functions shown in figure
\ref{channel-permissions}. Permissions can only be taken away, not gained, which
is evident from the types of the functions, for example: 

\begin{verbatim}
val read_poison_only : ('a, on * _ * on) channel -> 
                       ('a, on * off * on) channel
\end{verbatim}

Apart from the type, all of these functions are simply identity functions. We provide a
type alias \texttt{'a chan = ('a, on * on * on) channel} for people who don't
want to write the longer (often optional) type annotations that the permission
types incur. All the useful functions are provided, as shown in figure
\ref{channel-permissions}.

\begin{figure}[h]
\centering
\begin{tabular}{c|c|c|l}
Read & Write & Poison & Function \\
\hline
0 & 0 & 0 & (useless) \\
0 & 0 & 1 & poison\_only \\
0 & 1 & 0 & write\_only \\
0 & 1 & 1 & write\_poison\_only \\
1 & 0 & 0 & read\_only \\
1 & 0 & 1 & read\_poison\_only \\
1 & 1 & 0 & read\_write\_only \\
1 & 1 & 1 & (default) \\
\end{tabular}
\caption{Channel permissions}
\label{channel-permissions}
\end{figure}

\subsection{Processes}

The parallel construct shuffles its list of functions in order to expose any
accidental dependency on the order in which they are started as processes.
If the list is empty, then it returns. Otherwise it proceeds as follows.
Except from the last function in the shuffled list, each function is started,
and the resulting list of thread handles are then joined. The remaining
function is run in the current thread to avoid spawning more threads than
required. All exceptions are caught, and each overwrites the contents of a
reference (protected by a mutex) that is initially $None$. When all threads have
been joined, the reference is checked. If it's $None$ then it just returns.
Otherwise it throws the saved exception.

\newpage
\section{Test \& examples}
\label{testexamples}
We originally wanted to provide both a simple example of process networks with
a Fibonacci process, and a more complex example, and compare both to a similar
implementation with an existing library. 

However, we decided that since we do not have true hardware parallelism, there
was more value in providing an example that took advantage of overlapping I/O.
We thus decided to make a web proxy. 

Before we do that however, it would be nice to know what kind of limits the
libraries our own library is built on has.

\subsection{OCaml tests}
\label{ocamltests}
\begin{table}[!h]
  \begin{center}
    \begin{tabular}{|p{3cm}|p{8.5cm}|c|}
      \hline
      File name &
      Description &
      Result \\
      \hline
      maxthreads.ml (user thread) &
      The application creates as many threads as possible, once it reaches
      about 15.000 it stops spawning more threads.&
      OK \\
      \hline
      maxthreads.ml (system thread) &
      The application creates as many threads as possible, once it reaches
      about 100 it stops spawning more threads.&
      OK \\
      \hline
      nonblocking.ml &
      We run to processes concurrently. The first process whats for user input
      and the second process after a seconds delay reads the first line from
      the its own source code file and writes the line to stdout.&
      OK \\
      \hline
    \end{tabular} 
    \caption{The test checks OCaml implementation of the thread and I/O
library.}
    \label{testtable}
  \end{center}
\end{table}

\subsubsection{Maxthreads}
\label{testMaxthreads}
Both test can be seen in appendix \ref{appendixOcamltest}.

In this test we try to find an upper bound of how many threads we can create,
user threads and/or system threads. In the first case when using user threads we
find that after creating between 15.000 - 20.000 threads the application
freezes. We are not able to find any kind of documentation that can helps us
verify that it's a deadlock or a maximum number of threads allowed for an
application to create. If we run the test several times, we will see that
each application will be able to create about those 15.000 - 20.000 threads.

By reading the {\it The runtime system (ocamlrun)} documentation we found
out that by changing some size of the heap $s$ to about $1024$ words. Then
we are able to create more than twice as many threads. Changing the stack
option $l$, do not give more threads.

In the second test based on maxthreads, we use system threads and as before
the application freezes but just after creating about 100 threads. By changing
on the options of {\it ocamlrun} as before, do not give more threads.

\subsubsection{Nonblocking}
The test can be seen in appendix \ref{appendixOcamltest}.

To implement the web proxy we need to know if one of the processes is waiting
to recieve a chunk of data, if it block the I/O until it has recieved the data
or if another process that is also waiting for a chunck.

We discovered that OCaml support non-blocking I/O, in the documentation to
\emph{ThreadUnix}\footnote{The \emph{ThreadUnix} module is \emph{deprecated}
but all functionality is moved to the Unix module.} in appendix
\ref{appendixThreadunix} we read that we may block the calling thread but not
all the threads in the process. Even though the arguments of \emph{Mr. Leroy} is
to use the \emph{system threads} instead of \emph{user threads}, see appendix
\ref{appendixSysthreads}, OCaml offers since version $2.03$, see change log
in appendix \ref{appendixChangelog}, that the \emph{bytecode threads} standard
I/O descriptors are set to non-blocking mode. This gives us the possibility to
compile to both native-code, with the \emph{-thread} compiler flag, or
byte-code, with the \emph{-vmthread} compiler flag.

This means that  it will be no problem to have several clients waiting to
recieve data from our web proxy. An example could be a client that connects over
the web proxy to a very slow website. The website can only deliver a small
amount of data every second. Another client that also connects over the web
proxy to a fast website. While the first client waits to recieve data from the
web server, the second client can read chunks of data from the fast website.

So what we have done is that we run two processes concurrently, the first one
waits for the user input, while the second one reads a line from its own
code file after a second of waiting (\emph{Thread.delay}). As we can see in the
test the second process is able to read the line even if the first process waits,
hereby we can see that we don't have non-blocking I/O.

\subsection{OCamlCSP tests}
\label{ocamlcsptests}
\subsubsection{Channel permisions}
In order to perform this test, we use some of the implemented components
of {\it Legoland}, see appendix \ref{appendixLegoland}. The test can bee seen
in detail in appendix \ref{appendixOcamlcsptest}. One of the features this API
has is that you have the possibility to set read/write/poision permissions on
the channels. With this test we will demostrate where this is useful. What we
do is that we have two components that just counts integers. When the second
counter reaches $20$ we want to poison the whole network. But we have sat the
first count to only count to 10 and it will shutdown the hole network through
the {\it stop} component from the {\it Legoland} library. But this is a problem,
we don't want the first counter to shut down the network so we add
{\it write\_only} to counter components output channel. This will result in a
compiler error because the {\it stop} component once it's poisoned it propagates
the poison to all the other channels, but we have just defined our output
channel to only allow write.

We now make a {\it custom\_stop} component which only propagates poison to
the input channel. We are now able to compile and run the application knowing
that our first counter will never shutdown our network through poison.

\subsubsection{Alternation}
The results of the test can be seen in appendix \ref{appendixOcamlcsptest}.

Based on the same code file as the one used to permision, we added a small
{\it guard} test which read from the two counters components whenever one of
them are ready. By setting the first counter to only send 5 numbers, we can
actually check that when setting the second counter to the double we can see
that the {\it custom\_printer} component will see if any of the to
{\it read\_guards} are ready to read from the counters and because one stop
early it will keep reading from the second.

% Jeg var noedt til at fjerne dette, sorry! Der stod ikke hvordan Python-koden
% var blevet koert, og resultaterne kan derfor ikke rigtig tolkes. Det ville
% være fedt at have med til mundtlig dog.
%\subsection{Performance}
%\label{performance}
%Even though we don't set focus on performance and optimization, it's still
%interesting to see what kind of performance we get in the
%Commstime \cite{vinterpycsp} benchmark that's used to compare
%PyCSP against JCSP.
%
%We have tried to keep the code as as close to an exact copy of the PyCSP
%benchmark code as possible in OCaml. The results can be seen in appendix
%
%The results of the test can be seen in appendix \ref{appendixPerformance}. It
%has been run on a Macbook Pro 2,6 GHz Core 2 Duo with 4GB RAM and Mac OS 10.5.7
%and the results can be seen in appendix \ref{appendixPerformance}. Please note
%that we didn't apply any JIT compilation to the Python code, but executed it in
%the standard CPython implementation.

\subsection{Examples}
\label{examples}

\subsubsection{Fibonacci}
\begin{figure}[h]
  \begin{center}
    \begin{tikzpicture}[node distance   = 4 cm]
      \GraphInit[vstyle=Normal]
      \tikzset{LabelStyle/.style =   {draw}}
      \SetVertexNormal[TextColor = white,
                       LineColor = white]
      \Vertex{Out}
      \SetVertexNormal[Shape = circle,
                       TextColor = black,
                       LineWidth = 2pt]
      \WE(Out){delta2int}
      \WE(delta2int){prefixInt0}
      \WE(prefixInt0){prefixInt1}
      \SO(prefixInt0){pairsInt}
      \SetUpEdge[style={->,ultra thick},labelstyle = {draw}]
      \Edge[label=out](delta2int)(Out)
      \Edge[label=c2](prefixInt0)(delta2int)
      \Edge[label=c1](prefixInt1)(prefixInt0)
      \SetUpEdge[style={->,bend left,ultra thick},labelstyle = {draw}]
      \Edge[label=c3](delta2int)(pairsInt)
      \Edge[label=c4](pairsInt)(prefixInt1)
    \end{tikzpicture}
  \end{center}
  \caption{FibonacciInt, a CSP component from the Legoland Library.}
  \label{fibonaccicomp}
\end{figure}

This test, once we have implemented all the {\it Legoland}\cite{vintercsp}
components, was a very easy and straight forward task. Even though that it
looks like this network doesn't do much it was very useful to discover that
our first implementation didn't work correctly.

\begin{figure}[h]
  \begin{center}
    \begin{tikzpicture}[node distance   = 4 cm]
      \GraphInit[vstyle=Normal]
      \tikzset{LabelStyle/.style = {draw}}
      \SetVertexNormal[Shape = circle,
                       TextColor = black,
                       LineWidth = 2pt]
      \Vertex{FibonacciInt}
      \EA(FibonacciInt){Stop}
      \EA(Stop){Printer}
      \SetUpEdge[style={->,ultra thick},labelstyle = {draw}]
      \Edge[label=c1](FibonacciInt)(Stop)
      \Edge[label=c2](Stop)(Printer)
    \end{tikzpicture}
  \end{center}
  \caption{Fibonacci CSP network with stop component.}
  \label{fibonacci}
\end{figure}

Another thing was that we implemented our {\it Legoland} components as
recursive function, but not tail-recursive due to exception handling, after
running this application for a lot of iteration, about 75.000, we began to get
messages of stack overflow. Once we rewrote the components from recursive to
using {\it while true do} we were able to run more than a 1.000.000 iterations,
and there shouldn't be any inherent limit to the number of iterations.

A descriptive diagram on how this simple network works can be seen in figure
\ref{fibonaccicomp} and \ref{fibonacci} where we use the {\it Legoland
fibonacciInt} component running concurrently with a {\it stop} component which,
ensures that the network shuts down correctly after the number of iterations
given as the first parameter, and a {\it printer} component which prints out to
the screen the Fibonacci numbers.

Other examples on how to write some simple processes and them put them together
running concurrently in another process can be seen in our {\it CSP component 
library (Legoland)}, see  {\it appendix \ref{appendixLegoland}}.

\subsubsection{Web proxy}

The web proxy proxies all HTTP GET requests on a specific port. It serves as a
non-trivial example of an application built using the library. It also features
a cache that demonstrates how to implement shared knowledge with the library.
Additionally, it shows how to communicate with the outside world using sockets.
It is purely for demonstration purposes and not meant to be used in production.
This section will be easier to follow while looking at the code in appendix
\ref{appendixProxy}.

All the socket (and thus file) input/output is done via three general purpose
processes called \emph{file\_reader}, \emph{file\_line\_reader} and
\emph{file\_writer} from \emph{Cspu} (see appendix \ref{appendixCspu}). This
allows us to treat the sockets like channels.

The top process is called \emph{gateway}. Inside it, two processes run
concurrently: the \emph{cache} and the \emph{accept loop}.

The \emph{cache} process knows three channels: $i$, $o$ and $d$. When an URL is
written to $i$ it either writes $Some\,f$ on $o$, where $f$ is the file name of
a file holding the cached resource, or writes $None$ on $o$ if the resource is
not in the cache. Whenever a pair consisting of an URL and a filename is
written on $d$, it will add this to the cache. Note that it uses \emph{select}
to chose between reading from $i$ and $d$.

The \emph{accept loop} accepts an incoming socket connection. Then it runs
itself concurrently with the \emph{handler} process. Note that running
\emph{the rest of the process} concurrently with some other process is a
general technique for creating a dynamic number of worker processes. We shall
call resulting sockets from accepts \emph{client sockets}.

The \emph{handler} process reads the header from the client socket and extracts
the requested URL. It writes this to the cache which either responds with the
file name or with $None$. In the former case, it simply reads the cached
resource from the file and writes it to the client socket. In the latter case,
it becomes the \emph{http\_downloader} process.

The \emph{http\_downloader} process extracts the hostname, port and path from
the URL and opens a connection to the server specified by the hostname. We
shall call the resulting socket the \emph{server socket}. It then writes a
suitable HTTP header to the server socket and then becomes the
\emph{socket\_downloader} process.

The \emph{socket\_downloader} process creates a file for caching the resource
it is about to download. It then proceeds to read the resource from the
\emph{server socket}. This stream is duplicated using the \emph{delta} process
and written to the client socket and via the \emph{registrator} process to the
newly created cache file. 

The \emph{registrator} process process simply writes everything it reads from
its input channel to its output channel. However, when it detects successful
end of file (in the form of \emph{None}), it writes a pair (url, filename) to
the cache (using its $d$ channel), thus adding the file to the cache.

In order to test the proxy, we wrote a small file server and used \emph{wget}
as a client. The source code for the server and instructions for testing the
proxy can be found in appendix \ref{appendixProxy} together with the test
output. The tests ran successfully.


\newpage
\section{Conclusion}
\label{conclusion}

We set out to design a concurrency API inspired by CSP and the existing
libraries based on CSP in OCaml. The constructs we have provided are quite
similar to the corresponding constructs in CSP, and not much more verbose
syntactically. In addition, they have some useful properties, such as
starvation avoidance and support for termination of process networks. The
channel construct has also been generalized so that any number of processes can
read from and write to a single channel, and we do not sacrifize write guarded
processes. The channels carry typed messages and the implementation is type
safe. Standard ocamldoc documentation has been provided for all the constructs.

We did not provide true hardware parallelism, but there is nothing in the API
that prevents the implementation from supporting it, should OCaml ever get a
concurrent garbage collector. We have implemented an example of the kind of
application that the library is well suited for in form of a web proxy, and
provided reusable processes for mapping buffered sockets to channels.

One route to parallelism may be through distribution, by spawning actual
system processes (with separate memory spaces) and building a channel
abstraction on top of sockets. It is not obvious how to do this transparently
given our API, as it would take a lot of work to keep the lexical
scoping if \verb|Csp.parallel| might spawn real system processes, maybe even
on another computer across the network. Although OCaml does provide marshalling,
it is not clear how to expose the failures that a socket based channel
implementation would have to handle. Presumably, the hardest part would be to
figure out how to effectively synchronize communication over a network.
Searching the existing libraries for a solution would be a good starting point.

You could decide that distributed processes use a flat process model and
leave spawning of these processes up to the programmer. Additionally, you may
say that channels are exposed to such processes by a named socket, and that
exposed channels are buffered. With these assumptions it can be done with the 
Unix module, marshalling and the buffered socket channel abstraction we already
provided. However, you would lose synchronization for the exposed channels.

\appendix
\newpage
\section{Appendix: Documentation}
\label{appendixDoc}
The documentation can be created with following command:

\runtest{ocamldoc -html -d ../docs/ csp.mli}
\begin{center}
  \includepdf[pages=-]{../docs/csp.pdf}
\end{center}

\newpage
\section{Appendix: Source code}
\secttoc
\newpage
\label{appendixSrc}

\scriptsize
\subsection{API}
\label{appendixAPI}
\includecode{csp.mli}{../source/csp.mli}
\includecode{csp.ml}{../source/csp.ml}
\subsection{A CSP Utility Library}
\label{appendixCspu}
\includecode{cspu.ml}{../source/cspu.ml}
\subsection{A CSP Component Library (Legoland)}
\label{appendixLegoland}
\includecode{legoland.ml}{../source/legoland.ml}


\newpage
\section{Appendix: Test \& examples}
\secttoc
\newpage
\label{appendixTest}

\subsection{OCaml tests}
\label{appendixOcamltest}
\subsubsection{Maxthreads}
\includecode{maxthreads.ml}{../test/maxthreads.ml}
\runtest{export OCAMLRUNPARAM='b,s=1024k'}
\\
\runtest{ocamlc -vmthread unix.cma threads.cma maxthreads.ml -o maxthreads \&\&
  ./maxthreads}
\includeoutput{userMaxThreads.txt}{test/userMaxThreads.txt}
\runtest{ocamlc -thread unix.cma threads.cma maxthreads.ml -o maxthreads \&\&
  ./maxthreads}
\includeoutput{sysMaxThreads.txt}{test/sysMaxThreads.txt}

\subsubsection{Nonblocking}
\includecode{nonblocking.ml}{../test/nonblocking.ml}
\runtest{ocamlc -vmthread threads.cma unix.cma nonblocking.ml -o nonblocking
  \&\& ./nonblocking}
\includeoutput{nonblocking.txt}{test/nonblocking.txt}

\subsection{OCamlCSP tests}
\label{appendixOcamlcsptest}
\subsubsection{Channel permisions}
\includecode{permission.ml}{../test/permission.ml}
\runtest{./buildPermission.sh \&\& ./buildPermission}
\includeoutput{permision\_error.txt}{test/permision_error.txt}

\subsubsection{Alternation}
\includeoutput{alternation\_one\_guard.txt}{test/alternation_one_guard.txt}
\includeoutput{alternation\_poison.txt}{test/alternation_poison.txt}

%\subsection{Performance}
%\label{appendixPerformance}
%\subsubsection{Commstime}
%\includecode{commstime.ml}{../test/commstime.ml}
%\runtest{./buildCommstime.sh \&\& ./commstime}
%\includeoutput{ocamlcsp\_commstime.txt}{test/ocamlcsp_commstime.txt}
%\includeoutput{pycsp\_commstime.txt}{test/pycsp_commstime.txt}

\subsection{Examples}
\subsubsection{Fibonacci}
\includecode{fibCSP.ml}{../test/fibCSP.ml}
\runtest{./buildFibCSP.sh \&\& ./buildFibCSP}
\includeoutput{fibonacci.txt}{test/fibonacci.txt}

\newpage
\subsubsection{Web proxy}
\label{appendixProxy}
\includecode{proxy.ml}{../test/proxy.ml}
\includecode{server.rb}{../test/web/server.rb}
Start two sequential web servers (ruby):

\runtest{ruby server.rb 4040 0.1 \&}

\runtest{ruby server.rb 4041 0.3 \&}


Start the web proxy:

\runtest{./buildProxy.sh \&\& ./proxyCSP \&}


Add the web proxy to the terminal session:

\runtest{export http\_proxy=http://localhost:8080}


Retrieve the file foo.mp3 from the first web server:

\runtest{wget http://localhost:4040/foo.mp3}
\includeoutput{proxy\_get\_file\_first\_time.txt}{
  test/proxy_get_file_first_time.txt}

Note that the web server serves all its files from a directory called
\emph{mp3} inside the path in which it was started.

Retrieve the file foo.mp3 again from the first web server (cache):

\runtest{wget http://localhost:4040/foo.mp3}

\includeoutput{proxy\_get\_file\_second\_time.txt}{
  test/proxy_get_file_second_time.txt}


Retrieve concurrent the files bar.mp3 and foo.mp3 from the two web servers:

\includeoutput{proxy\_same\_time\_bar.txt}{
  test/proxy_same_time_bar.txt}
\includeoutput{proxy\_same\_time\_foo.txt}{
  test/proxy_same_time_foo.txt}

\newpage
\section{Appendix: Parallelism \& non-blocking I/O}
\secttoc
\newpage
\subsection{Why systhreads? (Xavier Leroy, November 2002)}
\label{appendixSysthreads}
{\tt
  \scriptsize
  \input{appendix/whySysthreads.txt}
  \normalsize
}

\newpage
\subsection{ThreadUnix module}
\label{appendixThreadunix}
This is generated by ocamldoc, which is why it does not have page numbers.
\begin{center}
  \includepdf[pages=-]{appendix/threadUnix.pdf}
\end{center}

\newpage
\subsection{Change log, Objective Caml 2.03}
\label{appendixChangelog}
{\tt
  \scriptsize
  \input{appendix/changeLog203.txt}
  \normalsize
}

\newpage
\subsection{Threads and Str (Xavier Leroy, September 2005)}
\label{appendixThreadsafestr}
{\tt
  \scriptsize
  \input{appendix/threadSafeStr.txt}
  \normalsize
}


% ----------------------------------------------------------------------
% Bibliography
% ----------------------------------------------------------------------
\newpage
\begin{thebibliography}{99}

\bibitem[Hoare 04]{hoare}
:\\
Communicating Sequential Processes\\
C. A. R. Hoare\\
Prentice Hall International; (June 24, 2004)\\
ISBN-10: 0-13-153271-5\\
ISBN-13: 978-0-13-153271-7\\
http://www.usingcsp.com/cspbook.pdf

\bibitem[OCaml]{ocaml}
:\\
Objective Caml\\
Xavier Leroy, Jérôme Vouillon, Damien Doligez, Didier Rémy\\
National Institute for Research in Computer and Control Sciences\\
http://caml.inria.fr/ocaml/\\
Last visited: $24^{th}$ july 2009

\bibitem[ConcurrentML]{concurrentml}
:\\
Concurrent Programming in ML\\
John H. Reppy\\
Cambridge University Press (August 13, 1999)\\
ISBN-10: 0521480892\\
ISBN-13: 978-0521480895\\
http://www.usingcsp.com/cspbook.pdf

\bibitem[PyCSP]{pycsp}
:\\
PyCSP - Communicating Sequential Processes for Python\\
John Markus Bjørndalen, Brian Vinter and Otto Anshus\\
Department of Computer Science, University of Tromsø and\\
Department of Computer Science, University of Copenhagen\\
http://www.cs.uit.no/$\sim$johnm/publications/pdf/bjorndalen2007pycsp.pdf\\
Last visited: $26^{th}$ july 2009

\bibitem[JCSP]{jcsp}
:\\
Communicating Sequential Processes for Java\texttrademark (JCSP)\\
Peter Welch and Paul Austin\\
University of Kent at Canterbury\\
http://www.cs.kent.ac.uk/projects/ofa/jcsp/\\
Last visited: $26^{th}$ july 2009

\newpage
\bibitem[C++CSP2]{cppcsp2}
:\\
C++CSP2: A Many-to-Many Threading Model for Multicore Architectures\\
Brown,  Neil C. C.\\
University of Kent at Canterbury\\
ISBN-13: 978-1586037673\\
http://www.cs.kent.ac.uk/projects/ofa/c++csp/\\
Last visited: $26^{th}$ july 2009

\bibitem[Occam]{occam}
:\\
Occam 2 Reference Manual\\
C. A. R. Hoare\\
Prentice Hall; (May 1988)\\
ISBN-10: 0136293123\\
ISBN-13: 978-0136293125

\bibitem[CHP]{chp}
:\\
CHP: Communicating Haskell Processes\\
Brown,  Neil C. C.\\
University of Kent at Canterbury\\
http://twistedsquare.com/CHP.pdf\\
Last visited: $28^{th}$ july 2009


\bibitem[Vinter, PyCSP]{vinterpycsp}
:\\
PyCSP. The beginning of a CSP library for Python\\
Brian Vinter\\
Department of Computer Science. University of Copenhagen\\
http://isis.ku.dk/kurser/blob.aspx?feltid=224718\\
Last visited: $20^{th}$ july 2009

\bibitem[Vinter, CSP]{vintercsp}
:\\
Threading\\
Brian Vinter\\
Department of Computer Science. University of Copenhagen\\
http://isis.ku.dk/kurser/blob.aspx?feltid=224185\\
Last visited: $20^{th}$ july 2009

\end{thebibliography}
% ----------------------------------------------------------------------
\end{document}
